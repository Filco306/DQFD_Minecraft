{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Simple env test.\n",
    "import json\n",
    "import select\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import snake_gym\n",
    "import minerl\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqfd_network():\n",
    "    def __init__(self):\n",
    "        self.state = tf.placeholder(shape=[None,64,64,3], dtype=tf.float32)\n",
    "        self.conv1 = tf.layers.conv2d(inputs=self.state, filters=32, kernel_size=[8,8], strides=[4,4], \n",
    "                                      padding='VALID', activation=tf.nn.relu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5),\n",
    "                                      bias_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5))\n",
    "        self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64, kernel_size=[4,4], strides=[2,2], \n",
    "                                      padding='VALID', activation=tf.nn.relu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5),\n",
    "                                      bias_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5))\n",
    "        self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=64, kernel_size=[3,3], strides=[1,1], \n",
    "                                      padding='VALID', activation=tf.nn.relu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5),\n",
    "                                      bias_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5))\n",
    "        self.flat = tf.layers.flatten(self.conv3)\n",
    "        self.out = tf.layers.dense(self.flat, 11, activation=tf.nn.softmax)\n",
    "        self.predict = tf.argmax(self.out, 1)\n",
    "\n",
    "        self.is_expert = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        \n",
    "        self.action = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.action, 11, dtype=tf.float32)\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.out, self.actions_onehot), axis=1)\n",
    "\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        #self.reg_loss = tf.reduce_sum([tf.reduce_mean(reg_l) for reg_l in tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)])\n",
    "        \n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.train_step = tf.train.AdamOptimizer(0.01).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(observation):\n",
    "    region_size = 8\n",
    "    obs = observation['pov']\n",
    "    obs = obs / 255\n",
    "    compass_angle = observation['compassAngle']\n",
    "\n",
    "    compass_angle_scale = 180\n",
    "    compass_scaled = compass_angle / compass_angle_scale\n",
    "    compass_channel = np.ones(shape=list(obs.shape[:-1]) + [1], dtype=obs.dtype) * compass_scaled\n",
    "    obs = np.concatenate([obs, compass_channel], axis=-1)\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-f6dd171be424>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-f6dd171be424>:19: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-f6dd171be424>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "train network\n",
      "File not found!\n",
      "File not found!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "Broken pipe!\n",
      "rAll: 1.0\n",
      "rAll: 1.0\n",
      "rAll: 1.0\n",
      "rAll: 5.0\n",
      "rAll: 0.0\n",
      "rAll: 0.0\n",
      "rAll: 4.0\n",
      "rAll: 2.0\n",
      "rAll: 0.0\n",
      "rAll: 1.0\n",
      "9 1.5 0.1\n",
      "rAll: 0.0\n",
      "rAll: 0.0\n",
      "rAll: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-4:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0f3a29d73126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-0f3a29d73126>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m#action['jump'] = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mobs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pov'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/minerl/env/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;31m# Receive the observation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_socket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;31m# Receive reward done and sent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/minerl/env/comms.py\u001b[0m in \u001b[0;36mrecv_message\u001b[0;34m(sock)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecv_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mlengthbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecvall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlengthbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kimbring2/Steam1/minerl-env/lib/python3.6/site-packages/minerl/env/comms.py\u001b[0m in \u001b[0;36mrecvall\u001b[0;34m(sock, count)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mnewbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnewbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    annealing_episodes = 100\n",
    "    startE = 0.1\n",
    "    endE = 0.1\n",
    "    e = startE\n",
    "    stepDrop = (startE - endE) / annealing_episodes\n",
    "    \n",
    "    network = dqfd_network()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    variables = tf.trainable_variables(scope=None)\n",
    "    saver = tf.train.Saver(variables, max_to_keep=5)\n",
    "    \n",
    "    model_path = '/media/kimbring2/Steam1/MineRL/model/MineRLNavigate-v0'\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "    #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    episodeBuffer = deque()\n",
    "    total_steps = 0\n",
    "    rList = []\n",
    "    \n",
    "    data_tree = minerl.data.make('MineRLTreechop-v0', data_dir='/media/kimbring2/6224AA7924AA5039/minerl_data')\n",
    "    \n",
    "    demo_step = 0\n",
    "    \n",
    "    # Get expert data\n",
    "    for state, action, reward, next_state, done in data_tree.sarsd_iter(num_epochs=500, max_sequence_len=2000):\n",
    "        demo_step += 1\n",
    "        #print(\"demo_step: \" + str(demo_step))\n",
    "        \n",
    "        length = (state['pov'].shape)[0]\n",
    "        #print(\"length: \" + str(length))\n",
    "        \n",
    "        s_batch = []\n",
    "        a_batch = []\n",
    "        d_batch = []\n",
    "        r_batch = []\n",
    "        s1_batch = []\n",
    "        e_batch = []\n",
    "        for i in range(0, length):\n",
    "            #print(\"s.shape: \" + str(s.shape))\n",
    "            \n",
    "            action_index = 11\n",
    "            camera_threshols = (abs(action['camera'][i][0]) + abs(action['camera'][i][1])) / 2.0\n",
    "            if (camera_threshols > 2.5):\n",
    "                if ( (action['camera'][i][1] < 0) & ( abs(action['camera'][i][0]) < abs(action['camera'][i][1]) ) ):\n",
    "                    if (action['attack'][i] == 0):\n",
    "                        action_index = 0\n",
    "                    else:\n",
    "                        action_index = 1\n",
    "                elif ( (action['camera'][i][1] > 0) & ( abs(action['camera'][i][0]) < abs(action['camera'][i][1]) ) ):\n",
    "                    if (action['attack'][i] == 0):\n",
    "                        action_index = 2\n",
    "                    else:\n",
    "                        action_index = 3\n",
    "                elif ( (action['camera'][i][0] < 0) & ( abs(action['camera'][i][0]) > abs(action['camera'][i][1]) ) ):\n",
    "                    if (action['attack'][i] == 0):\n",
    "                        action_index = 4\n",
    "                    else:\n",
    "                        action_index = 5\n",
    "                elif ( (action['camera'][i][0] > 0) & ( abs(action['camera'][i][0]) > abs(action['camera'][i][1]) ) ):\n",
    "                    if (action['attack'][i] == 0):\n",
    "                        action_index = 6\n",
    "                    else:\n",
    "                        action_index = 7\n",
    "            elif (action['forward'][i] == 1):\n",
    "                if (action['attack'][i] == 1):\n",
    "                    action_index = 8\n",
    "                elif (action['jump'][i] == 1):\n",
    "                    action_index = 9\n",
    "            else:\n",
    "                action_index = 10\n",
    "                \n",
    "            if (action_index == 11):\n",
    "                continue\n",
    "            \n",
    "            s = state['pov'][i] / 255.0\n",
    "            s_batch.append(s)\n",
    "            \n",
    "            a_batch.append(action_index)\n",
    "            \n",
    "            r_batch.append(reward[i])\n",
    "\n",
    "            s1 = next_state['pov'][i] / 255.0\n",
    "            s1_batch.append(s1)\n",
    "            \n",
    "            d_batch.append(done[i].astype(int))\n",
    "            e_batch.append(1) \n",
    "        \n",
    "        Q1 = sess.run(network.out, feed_dict={network.state:s1_batch})\n",
    "        end_multiplier = -((np.array(d_batch)) - 1)\n",
    "        \n",
    "        #print(\"a_batch: \" + str(a_batch))\n",
    "        #print(\"Q1.shape: \" + str(Q1.shape))\n",
    "        #print(\"Q1[a_batch].shape: \" + str(Q1[a_batch].shape))\n",
    "        \n",
    "        targetQ = []\n",
    "        for k in range(0, len(Q1)):\n",
    "            Q1[k, a_batch[k]] += 0.8 \n",
    "            targetQ.append(r_batch[k] + 0.99 * np.max(Q1[k]) * end_multiplier[k])\n",
    "        \n",
    "        #Q1[:,a_batch] += 0.8 \n",
    "        #targetQ = r_batch + 0.99 * np.max(Q1, axis=1) * end_multiplier\n",
    "\n",
    "        print(\"train network\")\n",
    "        _ = sess.run(network.train_step, feed_dict={network.state:s_batch, \n",
    "                                                    network.targetQ:targetQ,\n",
    "                                                    network.action:a_batch,\n",
    "                                                    network.is_expert:e_batch})\n",
    "        \n",
    "        if demo_step == 100:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    # Train DQN\n",
    "    env = gym.make(\"MineRLTreechop-v0\")\n",
    "    for i in range(annealing_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        obs = env.reset()\n",
    "        s = obs['pov'] / 255.0\n",
    "\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        steps = 0\n",
    "\n",
    "        if e > endE:\n",
    "            e -= stepDrop\n",
    "        \n",
    "        # The Q-Network\n",
    "        while True:\n",
    "            steps += 1\n",
    "            total_steps += 1\n",
    "            \n",
    "            # Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e:\n",
    "                action_index = np.random.randint(0,11)\n",
    "            else:\n",
    "                action_index = sess.run(network.predict, feed_dict={network.state:[s]})[0]\n",
    "            \n",
    "            action = env.action_space.noop()\n",
    "            if (action_index == 0):\n",
    "                action['camera'] = [0, -2,5]\n",
    "            elif (action_index == 1):\n",
    "                action['camera'] = [0, -2,5]\n",
    "                action['attack'] = 1\n",
    "            elif (action_index == 2):\n",
    "                action['camera'] = [0, 2.5]\n",
    "            elif (action_index == 3):\n",
    "                action['camera'] = [0, 2.5]\n",
    "                action['attack'] = 1\n",
    "            elif (action_index == 4):\n",
    "                action['camera'] = [-2.5, 0]\n",
    "            elif (action_index == 5):\n",
    "                action['camera'] = [-2.5, 0]\n",
    "                action['attack'] = 1\n",
    "            elif (action_index == 6):\n",
    "                action['camera'] = [2.5, 0]\n",
    "            elif (action_index == 7):\n",
    "                action['camera'] = [2.5, 0]\n",
    "                action['attack'] = 1\n",
    "            elif (action_index == 8):\n",
    "                action['forward'] = 1\n",
    "                action['attack'] = 1\n",
    "            elif (action_index == 9):\n",
    "                action['forward'] = 1\n",
    "                action['jump'] = 1\n",
    "            else:\n",
    "                action['attack'] = 1\n",
    "            #action['jump'] = 1\n",
    "            \n",
    "            obs1, r, d, _ = env.step(action)\n",
    "            s1 = obs1['pov'] / 255.0\n",
    "            \n",
    "            episodeBuffer.append((s,action_index,r,s1,d))\n",
    "            if len(episodeBuffer) > 50000:\n",
    "                episodeBuffer.popleft()\n",
    "\n",
    "            #if total_steps % 500 == 0:\n",
    "            #    saver.save(sess, model_path + '/model-' + str(total_steps) + '.cptk')\n",
    "                \n",
    "            batch_size = 512\n",
    "            if total_steps % (batch_size) == 0:\n",
    "                trainBatch = random.sample(episodeBuffer, batch_size)\n",
    "\n",
    "                s_batch = [d[0] for d in trainBatch]\n",
    "                a_batch = [d[1] for d in trainBatch]\n",
    "                d_batch = [d[4] for d in trainBatch]\n",
    "                d_batch = (np.array(d_batch)).astype(int)\n",
    "\n",
    "                r_batch = [d[2] for d in trainBatch]\n",
    "                s1_batch = [d[3] for d in trainBatch]\n",
    "                \n",
    "                Q1 = sess.run(network.out, feed_dict={network.state:s1_batch})\n",
    "                end_multiplier = -(d_batch - 1)\n",
    "                targetQ = r_batch + 0.99 * np.max(Q1, axis=1) * end_multiplier\n",
    "                \n",
    "                print(\"train network\")\n",
    "                _ = sess.run(network.train_step, feed_dict={network.state:s_batch, \n",
    "                                                            network.targetQ:targetQ,\n",
    "                                                            network.action:a_batch})\n",
    "            \n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "                break\n",
    "        \n",
    "        #jList.append(j)\n",
    "        print(\"rAll: \" + str(rAll))\n",
    "        rList.append(rAll)\n",
    "        \n",
    "        if len(rList) % 10 == 0:\n",
    "            print(i, np.mean(rList[-10:]), e)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "minerl-env",
   "language": "python",
   "name": "minerl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
